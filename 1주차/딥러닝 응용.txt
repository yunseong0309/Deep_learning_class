딥러닝 응용

깃허브 주소 보내기

weight -> 기울기
bias -> 출발점 (예를 들어 생각하는 기준점 -> 잎 또는 줄기의 관점 같은거)
f(x)=wx+b

인공지능에서 지능에 해당하는 기능은 무엇인가?


인공지능의 종류 3가지에 대해서 설명하시오 (지도학습, 반지도학습, 강화학습)


전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점은 무엇인가?


4.딥러닝과 머신러닝의 차이점은 무엇인가?
	입력-> 모델 -> 훈련 -> 결과
	딥러닝은 모델안에서 특징추출과 트레이닝이 이루어진다
	머신러닝은 특징추출을 먼저해서 입력값으로 넣는다


5.Classification과 Regression의 주된 차이점은?
	classfication:
	Regression: classfication을 잘게 나눈면 regression이 된다. (ex 온도)
	-> 둘다 원리는 같다


6. 머신러닝에서 차원의 저주(curse of dimensionality)란?
	차원이 많아질 수록 w,b 를 얻기가 힘들다 -> 과적합
	그래서 관련이 높은 특징과 없는 특징을 분류 -> feature selection ->규제
	특징을 없애는 방법 또는 특징의 가중치를 줄이는 방법이 있다.

Dimensionality Reduction는 왜 필요한가?


Ridge와 Lasso의 공통점과 차이점? (Regularization, 규제 , Scaling)


9.Overfitting vs. Underfitting
	오버피팅은 데이터의 노이즈도 학습하여 오히려 성능이 떨어짐

10.Feature Engineering과 Feature Selection의 차이점은?
		
11.전처리(Preprocessing)의 목적과 방법? (노이즈, 이상치, 결측치)
12.EDA(Explorary Data Analysis)란? 데이터의 특성 파악(분포, 상관관계)


13.회귀에서 절편과 기울기가 의미하는 바는? 딥러닝과 어떻게 연관되는가?
	1.activation function
	2.optinitev
	3.backpropagation
	4.found ++
	5.loss function
	6.one-hot encoding

14.Activation function 함수를 사용하는 이유? Softmax, Sigmoid 함수의 차이는?


15.Forward propagation, Backward propagation이란?
손실함수란 무엇인가? 가장 많이 사용하는 손실함수 4가지 종류는?
옵티마이저(optimizer)란 무엇일까? 옵티마이저와 손실함수의 차이점은?
경사하강법 의미는? (확률적 경사하강법, 배치 경사하강법, 미치 배치경사하강법)
교차검증, K-fold 교차검증의 의미와 차이
하이퍼파라미터 튜닝이란 무엇인가?
CNN의 합성곱의 역활은?
CNN의 풀링층의 역활은?
CNN의 Dense Layer의 역활은?
CNN의 stride, filter의 역활? 필터의 가중치는 어떻게 결정되는가?
RNN을 사용하는 이유와 한계점은?
LSTM을 사용하는 이유와 한계점은?
GRU을 사용하는 이유와 차별성은?
결정트리에서 불순도(Impurity) – 지니 계수(Gini Index)란 무엇인가?
앙상블이란 무엇인가?
부트 스트랩핑(bootstraping)이란 무엇인가?
배깅(Bagging)이란 무엇인가?
주성분 분석(PCA) 이란 무엇인가?
Dense Layer란 무엇인가?